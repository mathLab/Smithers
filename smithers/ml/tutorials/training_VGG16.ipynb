{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VGG16 - Tutorial\n",
    "\n",
    "In this tutorial we will present how to train a VGG16 network and create a checkpoint for the trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Firstly, we start by importing all the necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.insert(0, '/scratch/lmeneghe/Smithers/')\n",
    "\n",
    "from smithers.ml.models.vgg import VGG\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the proper device\n",
    "The following lines will detect if a gpu is available in the system running this tutorial. If that is the case, all the objects of the following tutorial will be allocated in the gpu, thus speeding up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda has been detected as the device which the script will be run on.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f\"{device} has been detected as the device which the script will be run on.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the model\n",
    "We use VGG16 as model, as implemented in ***smithers/ml/models/vgg.py***. The net is initialized using weights pre-trained on ImageNet, a common choice instead of using random ones (i.e. setting init_weights=True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded base model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VGGnet = VGG(cfg=None,\n",
    "             classifier='cifar',\n",
    "             batch_norm=False,\n",
    "             num_classes=10,\n",
    "             init_weights='imagenet').to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(VGGnet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of the CIFAR10 dataset\n",
    "As stated before, we use the CIFAR10 dataset (already implemented in PyTorch) to test our technique. It is a computer-vision dataset used for object recognition. It consists of 60000 32 Ã— 32 colour images divided in 10 non-overlapping classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.\n",
    "\n",
    "See https://www.cs.toronto.edu/~kriz/cifar.html for more details on this dataset and on how to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8 #this can be changed\n",
    "data_path = '../cifar/' \n",
    "# transform functions: take in input a PIL image and apply this\n",
    "# transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_dataset = datasets.CIFAR10(root=data_path + 'CIFAR10/',\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "train_labels = torch.tensor(train_loader.dataset.targets).to(device)\n",
    "targets = list(train_labels)\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "n_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset\n",
    "If we want to use a custom dataset, we need firstly to construct it, following for example the tutorial on the construction of a custom dataset for the problem of Image Recognition. Hence, the previuous cell will be substitute with the following one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from collections import OrderedDict\n",
    "from smithers.ml.imagerec_dataset import Imagerec_Dataset\n",
    "\n",
    "# load custom dataset for training and testing\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "data = pd.read_csv('../dataset_imagerec/dataframe.csv')\n",
    "data_path = '../dataset_imagerec/'\n",
    "# SPLIT OF THE DATASET\n",
    "batch_size = 128\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "dataset_size = len(data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "print('train data', len(train_indices))\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "resize_dim = [32, 32]\n",
    "\n",
    "dataset_imagerec = Imagerec_Dataset(data, data_path, resize_dim, transform)\n",
    "train_dataset = dataset_imagerec.getdata(train_indices)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_imagerec,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_imagerec,\n",
    "                                          batch_size=batch_size,\n",
    "                                          sampler=valid_sampler)\n",
    "\n",
    "data.sort_values(by=['encoded_labels'], inplace=True)\n",
    "classes = data['labels'].unique()\n",
    "#classes = ('class_1', 'class_2', 'class_3', 'class_4')\n",
    "n_class = len(classes)\n",
    "targets = list(dataset_imagerec.targets[train_indices])\n",
    "train_labels = torch.tensor(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase \n",
    "The following lines of code will train the network on the train images from the CIFAR10 dataset. Beware that training time can be very long and a gpu is recommended.\n",
    "\n",
    "It is possible to change the number of epochs for the training: if a large number is given, the network will perform better on the train images but will take longer to train, vice versa for a low number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss Value: 0.09345\n",
      "Epoch 2, Loss Value: 0.05922\n",
      "Epoch 3, Loss Value: 0.04876\n",
      "Epoch 4, Loss Value: 0.04112\n",
      "Epoch 5, Loss Value: 0.03649\n",
      "The network has been successfully trained for 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = VGGnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Let's print statistics at the end of the epoch\n",
    "        running_loss += loss.item()     # extract the loss value\n",
    "        if i==len(train_loader)-1:\n",
    "            print('Epoch {}, Loss Value: {:.5f}'.format\n",
    "                 (epoch + 1, running_loss / ((i+1)*batch_size)))\n",
    "            # zero the loss\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print(\"The network has been successfully trained for {} epochs.\".format(n_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy after the training phase\n",
    "Once we have trained our model we can check its accuracy on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAccuracy(net, test_loader, device):\n",
    "    '''\n",
    "    Function for testing the accuracy of the model.\n",
    "\n",
    "    :param nn.Module net: network under consideration\n",
    "    :param iterable test_loader: iterable object, it load the dataset for\n",
    "            testing. It iterates over the given dataset, obtained combining a\n",
    "            dataset(images, labels) and a sampler.\n",
    "    '''\n",
    "    net.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    net.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = net(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "def testClasses(net, n_classes, test_loader, classes, device):\n",
    "    '''\n",
    "    Function testing the accuracy reached for each class\n",
    "    composing the dataset.\n",
    "\n",
    "    :param nn.Module net: network under consideration\n",
    "    :param int n_classes: number of classes composing the dataset\n",
    "    :param iterable test_loader: iterable object, it load the dataset for\n",
    "            testing. It iterates over the given dataset, obtained combining a\n",
    "            dataset(images, labels) and a sampler.\n",
    "    '''\n",
    "    class_correct = list(0. for i in range(n_classes))\n",
    "    class_total = list(0. for i in range(n_classes))\n",
    "    net.eval()\n",
    "    net.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)            \n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            if len(labels)==1:\n",
    "                c = torch.tensor([c])\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        print('Accuracy of {} : {:.2f}%'.format(\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy over the whole test set is 87.51%\n",
      "Accuracy of airplane : 92.30%\n",
      "Accuracy of automobile : 96.80%\n",
      "Accuracy of bird : 87.90%\n",
      "Accuracy of cat : 82.40%\n",
      "Accuracy of deer : 87.30%\n",
      "Accuracy of dog : 73.80%\n",
      "Accuracy of frog : 89.50%\n",
      "Accuracy of horse : 87.30%\n",
      "Accuracy of ship : 92.80%\n",
      "Accuracy of truck : 85.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = testAccuracy(VGGnet, test_loader, device)\n",
    "print('The accuracy over the whole test set is {:.2f}%'.format(accuracy))\n",
    "testClasses(VGGnet, n_classes, test_loader, classes, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a checkpoint of the state of the network\n",
    "Once the training is done, the state of the network should be saved for a later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "torch.save(copy.deepcopy(VGGnet), 'check_vgg.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading state of the network from a checkpoint file\n",
    "Once the state of the network has been saved in a ***.pth*** file, we can load it for a futher use, as an additional training or other tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGnet = torch.load('check_vgg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy over the whole test set is 87.51%\n",
      "Accuracy of airplane : 92.30%\n",
      "Accuracy of automobile : 96.80%\n",
      "Accuracy of bird : 87.90%\n",
      "Accuracy of cat : 82.40%\n",
      "Accuracy of deer : 87.30%\n",
      "Accuracy of dog : 73.80%\n",
      "Accuracy of frog : 89.50%\n",
      "Accuracy of horse : 87.30%\n",
      "Accuracy of ship : 92.80%\n",
      "Accuracy of truck : 85.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = testAccuracy(VGGnet, test_loader, device)\n",
    "print('The accuracy over the whole test set is {:.2f}%'.format(accuracy))\n",
    "testClasses(VGGnet, n_classes, test_loader, classes, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c5bf16c94eb6f9341fa612a12f652937166e39821fa969ec7095b77ab48ffd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

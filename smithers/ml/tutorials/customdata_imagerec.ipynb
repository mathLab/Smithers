{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFsuXpUwQn80"
   },
   "source": [
    "# Custom Dataset for  image classification\n",
    "In this tutorial, we will describe how to create and use a custom dataset for the aim of image classification, following https://www.kaggle.com/basu369victor/pytorch-tutorial-the-classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3D2nXrfRFEj"
   },
   "source": [
    "## Custom dataset\n",
    "First of all, you need to collect all the images you need to create the dataset (preferably ~1000 images per category) and define the different categories in exam.\n",
    "At the end the directory ***dataset*** containing all your images should have a structure like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](structure_img.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where each image has been placed inside the subdirectory class_i corresponding to the class it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ftu0AINGQ67c"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named torch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bbfeeb2932d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Neural networks can be constructed using the torch.nn package.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named torch"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#define the device\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "WVm1fmhQZarc",
    "outputId": "201d08fd-65db-4627-9ca1-310727696bfd"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-64f01e6f276f>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    for class in os.listdir(BASE_PATH):\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "image = []\n",
    "labels = []\n",
    "#path to the directory containing your dataset\n",
    "data_path = 'dataset_imagerec/'\n",
    "for file in os.listdir(data_path):\n",
    "    if os.path.isdir(os.path.join(data_path, file)):\n",
    "        for img in os.listdir(os.path.join(data_path, file)):\n",
    "            image.append(c)\n",
    "            labels.append(file)\n",
    "\n",
    "# Creation of a csv Data-frasmithers.me from the raw dataset. You might not have to follow\n",
    "# this step if you are already provided with csv file which contains the desired \n",
    "# input and target value.\n",
    "data = {'Images':image, 'labels':labels} \n",
    "data = pd.DataFrame(data) \n",
    "data.head()\n",
    "\n",
    "lb = LabelEncoder()\n",
    "data['encoded_labels'] = lb.fit_transform(data['labels'])\n",
    "data.head()\n",
    "\n",
    "# save the csv file inside the dataset directory \n",
    "data.to_csv('dataset_imagerec/dataframe.csv', index=False)\n",
    "#in order to import the file run this command\n",
    "#data = pd.read_csv('dataset_imagerec/dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY2TmApGdycf"
   },
   "source": [
    "## Splitting of the dataset\n",
    "The dataset needs to be split between the train and test process. Usually you will use 80% of all the images for the training phase and the remainig 20% for the testing phase.\n",
    "\n",
    "There are two ways to do this: one is to do it from scratch, the other one is by using ***train_test_split*** function ***from scikit-learn*** (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q9IhpuJvdFuR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b6b00ee0a5dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdataset_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdataset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "dataset_size = len(data)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images Preparation\n",
    "After collecting the images, it is necessary to apply them some transformations in order to be used during the training and testing phases.\n",
    "\n",
    "- ***Transforms*** are common image transformations, that can be chained together using ***Compose***.\n",
    "- You need to convert a PIL Image or numpy.ndarray to tensor using ***transforms.ToTensor()***. It converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8\n",
    "- The tensor images should be ***normalized*** with mean and standard deviation. Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, the transformation ***transforms.Normalize*** will normalize each channel of the input torch.*Tensor i.e. input[channel] = (input[channel] - mean[channel]) / std[channel].\n",
    "\n",
    "Here you can find an example of transormation that can be applied to the images of your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom dataset class\n",
    "You now need to create a dataset class to be used as first argument in the function ***torch.utils.data.DataLoader()***.\n",
    "\n",
    "The skeleton of your custom dataset class has to be as the one in the cell below. It must contain the following functions to be used by data loader later on.\n",
    "- ***__init__()*** function is where the initial logic happens like reading a csv, assigning transforms, filtering data, etc.\n",
    "- ***__getitem__()*** function returns the data and labels. This function is called from dataloader like this:\n",
    "\n",
    "     img, label = MyCustomDataset.***__getitem__***(99)  # For 99th item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class MyCustomDataset(Dataset):\n",
    "    def __init__(self, ...):\n",
    "        # stuff\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # stuff\n",
    "        return (img, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return count # of how many examples(images) you have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of how you can create this custom dataset class is the following (see also  ***object_detector/imagerec_dataset.py***):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Imagerec_Dataset(Dataset):\n",
    "    def __init__(self, img_data, img_path, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.img_data = img_data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.img_path,self.img_data.loc[index, 'labels'],\n",
    "                                self.img_data.loc[index, 'Images'])\n",
    "        image = Image.open(img_name)\n",
    "        #image = image.convert('RGB')\n",
    "        image = image.resize((300,300))\n",
    "        label = torch.tensor(self.img_data.loc[index, 'encoded_labels'])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = transforms.ToTensor()(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the class for your custom dataset, you can create it and use it inside the function ***torch.utils.data.DataLoader()*** as described in the following part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Imagerec_Dataset(data, data_path, transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=test_sampler)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "customdata_imagerec.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
